{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8305bc2-9efd-43a2-9f67-44f862342c07",
   "metadata": {},
   "source": [
    "# Construindo um Agente **ReAct** do Zero\n",
    "\n",
    "O padrão *ReAct* (Reasoning + Acting, que significa 'Raciocínio e Ação') permite que um modelo de linguagem (LLM) faça mais do que apenas responder perguntas. Ele pode, por exemplo, pesquisar informações na Wikipedia ou realizar cálculos. Nesse padrão, ensinamos o modelo a pedir para realizar essas ações e depois usamos os resultados dessas ações para melhorar suas respostas.\n",
    "\n",
    "O [ReAct](https://react-lm.github.io/) permite que um modelo de linguagem execute ações externas, como fazer pesquisas ou cálculos, e integre os resultados para aprimorar suas respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c8fcc",
   "metadata": {},
   "source": [
    "### Modelo LLM \n",
    "Neste código, utilizaremos a API da *OpenAI* e o modelo *gpt-4o-mini*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7df81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize a sua chave da API da OpenAI ou obtenha uma em: \n",
    "# https://platform.openai.com/account/api-keys\n",
    "\n",
    "import getpass\n",
    "key = getpass.getpass(\"Insira sua chave da API da OpenAI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81278257-1407-4955-988b-35aa237ed2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import re\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from sympy import sympify\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b6c3ab-d56a-47c1-8144-b54fb744c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá! Como posso ajudar você hoje?\n"
     ]
    }
   ],
   "source": [
    "# Testando o modelo gpt-4o-mini\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "prompt = \"Olá, ChatGPT!\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{'role':'user', 'content': prompt}]\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37659d5-aea5-49ed-823f-add67d779b9d",
   "metadata": {},
   "source": [
    "### 01 - Criando a classe do Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab542e1-cc4d-46de-bc1f-9c59f34120e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agente:\n",
    "    \"\"\"\n",
    "    Classe Agente que gerencia interações com um modelo de linguagem. \n",
    "    Inicializa o contexto da mensagem do sistema, adiciona entradas do usuário \n",
    "    e chama o modelo para gerar respostas.\n",
    "\n",
    "    Atributos:\n",
    "        system (str): Mensagem inicial do sistema. Se fornecida, é adicionada à lista de mensagens.\n",
    "        mensagens (List[Dict[str, str]]): Histórico de mensagens trocadas entre o usuário, sistema e o modelo.\n",
    "\n",
    "    Métodos:\n",
    "        __call__(prompt: str) -> str:\n",
    "            Recebe um prompt do usuário, adiciona ao histórico de mensagens, executa o modelo e retorna a resposta.\n",
    "        \n",
    "        executar(model: str = \"gpt-4o-mini\", temperature: float = 0) -> str:\n",
    "            Executa o modelo de linguagem com o histórico de mensagens atual e retorna a resposta.\n",
    "    \"\"\"\n",
    "    def __init__(self, system: str = \"\") -> None:\n",
    "        self.system: str = system\n",
    "        self.mensagens: List[Dict[str, str]] = []\n",
    "\n",
    "        if self.system:\n",
    "            self.mensagens.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, prompt: str) -> str:\n",
    "        self.mensagens.append({\"role\": \"user\", \"content\": prompt})\n",
    "        resultado: str = self.executar()\n",
    "        self.mensagens.append({\"role\": \"assistant\", \"content\": resultado})\n",
    "        return resultado\n",
    "\n",
    "    def executar(self, model: str = \"gpt-4o-mini\", temperature: float = 0) -> str:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            messages=self.mensagens\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33cddb-258e-4ab9-999b-65e7d5fa0682",
   "metadata": {},
   "source": [
    "### 02 - Criando o Prompt **ReAct**\n",
    "*Thought, Action, PAUSE, Observation*...PENSAMENTO, AÇÃO, PAUSA, OBSERVAÇÃO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0b092c-cce2-48f0-8acc-60b97c681143",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Você opera em um loop de PENSAMENTO, AÇÃO, PAUSA, OBSERVAÇÃO.\n",
    "No final do loop, você produz uma Resposta.\n",
    "\n",
    "Use o PENSAMENTO para descrever suas reflexões sobre a pergunta que lhe foi feita.\n",
    "Use a AÇÃO para executar uma das ações disponíveis para você - então retorne à PAUSA.\n",
    "A OBSERVAÇÃO será o resultado da execução dessas ações.\n",
    "\n",
    "Suas ações disponíveis são:\n",
    "\n",
    "calcular:\n",
    "ex.: calcular: 4 * 7 / 3\n",
    "Executa um cálculo e retorna o número - usa Python, então, certifique-se de usar a sintaxe de ponto flutuante, se necessário.\n",
    "\n",
    "obter_custo:\n",
    "ex.: obter_custo: teclado\n",
    "Retorna o custo de um teclado.\n",
    "\n",
    "obter_clima_atual:\n",
    "ex.: obter_clima_atual: Brasília\n",
    "Retorna a temperatura de uma cidade.\n",
    "\n",
    "wikipedia:\n",
    "ex.: wikipedia: LangChain\n",
    "Retorna um resumo de uma pesquisa no Wikipedia.\n",
    "\n",
    "Sempre procure informações no Wikipedia se tiver a oportunidade de fazê-lo.\n",
    "\n",
    "Exemplo de sessão #1:\n",
    "\n",
    "Pergunta: Quanto custa um monitor?\n",
    "PENSAMENTO: Eu deveria verificar o custo de um monitor usando obter_custo.\n",
    "AÇÃO: obter_custo: monitor\n",
    "PAUSA\n",
    "\n",
    "Você será chamado novamente com isto:\n",
    "\n",
    "OBSERVAÇÃO: Um monitor custa R$ 799,00.\n",
    "\n",
    "Você então gera a resposta:\n",
    "\n",
    "RESPOSTA: Um monitor custa R$ 799,00.\n",
    "\n",
    "\n",
    "Exemplo de sessão #2:\n",
    "\n",
    "Pergunta: Qual é a capital da França?\n",
    "PENSAMENTO: Eu deveria procurar a França no Wikipedia.\n",
    "AÇÃO: wikipedia: França\n",
    "PAUSA\n",
    "\n",
    "Você será chamado novamente com isto:\n",
    "\n",
    "OBSERVAÇÃO: A França é um país. A capital é Paris.\n",
    "\n",
    "Você então gera a resposta:\n",
    "\n",
    "RESPOSTA: A capital da França é Paris.\n",
    "\n",
    "\n",
    "Exemplo de sessão #3:\n",
    "\n",
    "Pergunta: Como está o tempo em São Paulo?\n",
    "PENSAMENTO: Eu deveria obter a temperatura na cidade de São Paulo usando obter_clima_atual.\n",
    "AÇÃO: obter_clima_atual: São Paulo\n",
    "PAUSA\n",
    "\n",
    "Você será chamado novamente com isto:\n",
    "\n",
    "OBSERVAÇÃO: 21°C\n",
    "\n",
    "Você então gera a resposta:\n",
    "\n",
    "RESPOSTA: A temperatura atual em São Paulo é 21°C.\n",
    "\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed56d0-ee48-4ea5-8c64-0cd3d369da6b",
   "metadata": {},
   "source": [
    "### 03 - Criando as ferramentas (*tools*)\n",
    "Com as ferramentas (funções em Python), podemos realizar chamadas de API e executar seu próprio código, expandindo as capacidades do ambiente original para o qual a IA foi projetada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac222ec-c233-4586-a03b-7eac049a682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular(expressao: str) -> float:\n",
    "    \"\"\"\n",
    "    Avalia uma expressão matemática fornecida em forma de string e retorna o resultado\n",
    "    com no máximo duas casas decimais. A função utiliza a biblioteca SymPy. \n",
    "\n",
    "    Args:\n",
    "        expressao (str): A expressão matemática a ser avaliada, por exemplo, \"(2 * 10) + (3 * 15)\".\n",
    "    \n",
    "    Returns:\n",
    "        float: O resultado da expressão avaliada com no máximo duas casas decimais.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resultado = sympify(expressao).evalf()\n",
    "        return round(float(resultado), 2)\n",
    "    except Exception as e:\n",
    "        return f\"Erro: {e}\"\n",
    "\n",
    "\n",
    "def obter_custo(item: str) -> str:\n",
    "    \"\"\"\n",
    "    Função que simula a chamada a uma API de uma loja fictícia.\n",
    "    Retorna o custo de um item de tecnologia.\n",
    "\n",
    "    Args:\n",
    "        item (str): O nome do item de tecnologia.\n",
    "\n",
    "    Returns:\n",
    "        str: A mensagem com o preço do item ou uma mensagem genérica para outros itens.\n",
    "    \"\"\"\n",
    "    if item == 'mouse':\n",
    "        return 'Um mouse custa R$ 99,90'\n",
    "    elif item == 'teclado':\n",
    "        return 'Um teclado custa R$ 149,90'\n",
    "    elif item == 'monitor':\n",
    "        return 'Um monitor custa R$ 799,00'\n",
    "    else:\n",
    "        return 'Demais itens custam R$ 199,00.'\n",
    "\n",
    "\n",
    "def obter_clima_atual(cidade: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Obtém a temperatura atual de uma cidade usando a API do wttr.in.\n",
    "\n",
    "    Args:\n",
    "        cidade (str): O nome da cidade para a qual se deseja obter o clima.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: Uma string formatada com a temperatura atual em Celsius.\n",
    "        Retorna `None` se houver algum erro na requisição ou nos dados.\n",
    "    \"\"\"\n",
    "    base_url = f\"http://wttr.in/{cidade}?format=j1\"\n",
    "    response = requests.get(base_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    try:\n",
    "        temperatura = data['current_condition'][0]['temp_C']\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "\n",
    "    return f\"{temperatura}°C\"\n",
    "\n",
    "\n",
    "def wikipedia(termo_busca: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Faz uma consulta à API do Wikipedia e retorna o 'snippet' do primeiro resultado encontrado.\n",
    "\n",
    "    Args:\n",
    "        termo_busca (str): O termo de busca a ser consultado na Wikipedia.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: O snippet (trecho) do primeiro resultado encontrado. Retorna `None` se não houver resultados.\n",
    "    \"\"\"\n",
    "    response = requests.get('https://en.wikipedia.org/w/api.php', params={\n",
    "        'action': 'query',\n",
    "        'list': 'search',\n",
    "        'srsearch': termo_busca,\n",
    "        'format': 'json'\n",
    "    })\n",
    "    results = response.json().get('query').get('search', [])\n",
    "    \n",
    "    if not results:\n",
    "        return None\n",
    "    return results[0]['snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b116bdfa-193a-48f8-b959-cb32c8a5ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário que mapeia os nomes das ferramentas para as próprias funções\n",
    "ferramentas = {\n",
    "    'calcular': calcular,\n",
    "    'obter_custo': obter_custo,\n",
    "    'obter_clima_atual': obter_clima_atual,\n",
    "    'wikipedia': wikipedia,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f75b29-e44e-4a22-bd8b-cd7d9cbac2d0",
   "metadata": {},
   "source": [
    "### 04 - Testando o Agente - Passo a Passo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1441715",
   "metadata": {},
   "source": [
    "#### Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223dc112-66f7-44bf-aecc-32682be16cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Eu deveria verificar o custo de um mouse usando obter_custo.  \n",
      "AÇÃO: obter_custo: mouse  \n",
      "PAUSA\n"
     ]
    }
   ],
   "source": [
    "# criando uma instância do Agente\n",
    "agente = Agente(prompt)\n",
    "\n",
    "resultado = agente('Quanto custa um mouse?')\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4fa06a7-27d2-49df-bb3b-285a9e83a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVAÇÃO: Um mouse custa R$ 99,90\n"
     ]
    }
   ],
   "source": [
    "# criando o próximo prompt, que será utilizado como uma Observação e enviado ao modelo de linguagem.\n",
    "proximo_prompt = f\"OBSERVAÇÃO: {obter_custo('mouse')}\"\n",
    "print(proximo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845f49d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPOSTA: Um mouse custa R$ 99,90.\n"
     ]
    }
   ],
   "source": [
    "# Resposta final do Agente\n",
    "print(agente(proximo_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50b8fe80-ad0d-4bf2-8933-a6a930d4ca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Quanto custa um mouse?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'PENSAMENTO: Eu deveria verificar o custo de um mouse usando obter_custo.  \\nAÇÃO: obter_custo: mouse  \\nPAUSA'},\n",
       " {'role': 'user', 'content': 'OBSERVAÇÃO: Um mouse custa R$ 99,90'},\n",
       " {'role': 'assistant', 'content': 'RESPOSTA: Um mouse custa R$ 99,90.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histórico de mensagens do Agente\n",
    "agente.mensagens[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790068b",
   "metadata": {},
   "source": [
    "#### Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b04f09ab-26f4-42f6-8d29-281fb6d86831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Eu preciso verificar o custo de um teclado e de um mouse para calcular o total. Primeiro, vou obter o custo do teclado. \n",
      "AÇÃO: obter_custo: teclado\n",
      "PAUSA\n"
     ]
    }
   ],
   "source": [
    "agente = Agente(prompt)\n",
    "\n",
    "pergunta = \"Eu quero comprar uma teclado e um mouse. Quanto eles custam no total?\"\n",
    "print(agente(pergunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe7afaac-b579-4768-857e-dcd17dbfd9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVAÇÃO: Um teclado custa R$ 149,90\n"
     ]
    }
   ],
   "source": [
    "proximo_prompt = f'OBSERVAÇÃO: {obter_custo(\"teclado\")}'\n",
    "print(proximo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ec1952-b5ea-4a8e-8e55-7b26cd0df865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Agora que eu tenho o custo do teclado, preciso verificar o custo do mouse para poder calcular o total. \n",
      "AÇÃO: obter_custo: mouse\n",
      "PAUSA\n"
     ]
    }
   ],
   "source": [
    "# Retorna para o Agente após a primeira observação\n",
    "print(agente(proximo_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "519b4cbf-d523-486e-9142-40e622803454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVAÇÃO: Um mouse custa R$ 99,90\n"
     ]
    }
   ],
   "source": [
    "proximo_prompt = f'OBSERVAÇÃO: {obter_custo(\"mouse\")}'\n",
    "print(proximo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3e7d78-c6a8-4506-b801-6d01597ee0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Agora que tenho os custos de ambos, o teclado custa R$ 149,90 e o mouse R$ 99,90. Vou calcular o total somando esses valores. \n",
      "AÇÃO: calcular: 149.90 + 99.90\n",
      "PAUSA\n"
     ]
    }
   ],
   "source": [
    "# Retorna para o Agente após a segunda observação\n",
    "print(agente(proximo_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35adb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVAÇÃO: 249.8\n"
     ]
    }
   ],
   "source": [
    "proximo_prompt = f'OBSERVAÇÃO: {calcular(\"149.90 + 99.90\")}'\n",
    "print(proximo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec32795c-da1c-4595-aa94-b07739f6aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPOSTA: O custo total de um teclado e um mouse é R$ 249,80.\n"
     ]
    }
   ],
   "source": [
    "# Resposta final do Agente\n",
    "print(agente(proximo_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992dd437",
   "metadata": {},
   "source": [
    "#### Exemplo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d49234c-267e-4ba6-84ef-1a0dc30041f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Eu deveria procurar informações sobre LangChain no Wikipedia para obter um resumo sobre o assunto.  \n",
      "AÇÃO: wikipedia: LangChain  \n",
      "PAUSA\n"
     ]
    }
   ],
   "source": [
    "agente = Agente(prompt)\n",
    "\n",
    "pergunta = \"LangChain\"\n",
    "print(agente(pergunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de51ed0-1cb3-4fee-842f-e59b92e79f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVAÇÃO: Expression Language&quot;. <span class=\"searchmatch\">langchain</span>.dev. 2023-08-01. Retrieved 2024-07-08. &quot;Introducing <span class=\"searchmatch\">Lang</span>Serve, the best way to deploy your <span class=\"searchmatch\">Lang</span><span class=\"searchmatch\">Chains</span>&quot;. <span class=\"searchmatch\">LangChain</span> Blog. 2023-10-12\n"
     ]
    }
   ],
   "source": [
    "# chamando a função wikipedia() e criando o próximo prompt\n",
    "proximo_prompt = f'OBSERVAÇÃO: {wikipedia(pergunta)}'\n",
    "print(proximo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "545e1f24-3a33-4076-a591-28841325a3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPOSTA: LangChain é uma ferramenta que facilita a construção de aplicações que utilizam modelos de linguagem. Ela permite a criação de \"chains\" (cadeias) que conectam diferentes componentes, como modelos de linguagem, APIs e bancos de dados, para construir fluxos de trabalho complexos e interativos.\n"
     ]
    }
   ],
   "source": [
    "# Resposta final do Agente\n",
    "print(agente(proximo_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cf048c1-28c6-4f05-b0ec-668d22720114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'LangChain'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'PENSAMENTO: Eu deveria procurar informações sobre LangChain no Wikipedia para obter um resumo sobre o assunto.  \\nAÇÃO: wikipedia: LangChain  \\nPAUSA'},\n",
       " {'role': 'user',\n",
       "  'content': 'OBSERVAÇÃO: Expression Language&quot;. <span class=\"searchmatch\">langchain</span>.dev. 2023-08-01. Retrieved 2024-07-08. &quot;Introducing <span class=\"searchmatch\">Lang</span>Serve, the best way to deploy your <span class=\"searchmatch\">Lang</span><span class=\"searchmatch\">Chains</span>&quot;. <span class=\"searchmatch\">LangChain</span> Blog. 2023-10-12'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'RESPOSTA: LangChain é uma ferramenta que facilita a construção de aplicações que utilizam modelos de linguagem. Ela permite a criação de \"chains\" (cadeias) que conectam diferentes componentes, como modelos de linguagem, APIs e bancos de dados, para construir fluxos de trabalho complexos e interativos.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histórico de mensagens do Agente\n",
    "agente.mensagens[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f5200",
   "metadata": {},
   "source": [
    "#### Exemplo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0deb2a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Eu deveria obter a temperatura na cidade de Santos usando obter_clima_atual.  \n",
      "AÇÃO: obter_clima_atual: Santos  \n",
      "PAUSA\n"
     ]
    }
   ],
   "source": [
    "agente = Agente(prompt)\n",
    "\n",
    "pergunta = \"Como está o tempo em Santos?\"\n",
    "print(agente(pergunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b36ca319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVAÇÃO: 25°C\n"
     ]
    }
   ],
   "source": [
    "proximo_prompt = f'OBSERVAÇÃO: {obter_clima_atual(\"Santos\")}'\n",
    "print(proximo_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48f592b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPOSTA: A temperatura atual em Santos é 25°C.\n"
     ]
    }
   ],
   "source": [
    "# Resposta final do Agente\n",
    "print(agente(proximo_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0e4a731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Como está o tempo em Santos?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'PENSAMENTO: Eu deveria obter a temperatura na cidade de Santos usando obter_clima_atual.  \\nAÇÃO: obter_clima_atual: Santos  \\nPAUSA'},\n",
       " {'role': 'user', 'content': 'OBSERVAÇÃO: 25°C'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'RESPOSTA: A temperatura atual em Santos é 25°C.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histórico de mensagens do Agente\n",
    "agente.mensagens[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e775ea",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e578c67-42d6-4d9f-9cb8-b2dceffcf5a7",
   "metadata": {},
   "source": [
    "### Automatizando o Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "808c48a0-3070-49c9-af2f-395d26992476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo um regex para encontrar a string 'AÇÃO'\n",
    "acao_re = re.compile(r'^AÇÃO: (\\w+): (.*)$')  # python regular expression to select Action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36c0e6e2-ec80-4f0c-8a92-60128fa3eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamar_agente(pergunta: str, max_turns: int = 5) -> str:\n",
    "    i: int = 0\n",
    "    bot: Agente = Agente(prompt)\n",
    "    proximo_prompt: str = pergunta\n",
    "\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        resultado = bot(proximo_prompt)\n",
    "        print(resultado)\n",
    "\n",
    "         # usando a regex para analisar a resposta do Agente\n",
    "        acoes = [ \n",
    "            acao_re.match(a) for a in resultado.split('\\n') if acao_re.match(a)\n",
    "        ]\n",
    "\n",
    "        if acoes:\n",
    "            acao, acao_input = acoes[0].groups() \n",
    "\n",
    "            if acao not in ferramentas:\n",
    "                raise Exception(f'Ação desconhecida: {acao}: {acao_input}')\n",
    "\n",
    "            print(f' -- executando --> {acao} {acao_input}')\n",
    "            observacao = ferramentas[acao](acao_input) \n",
    "           \n",
    "            print(f'OBSERVAÇÃO: {observacao}')\n",
    "            proximo_prompt = f'OBSERVAÇÃO: {observacao}'\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "484fc260-8051-49c6-8795-b5e2e52df8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Primeiro, preciso obter o custo de um monitor e de um mouse para calcular o total da compra de 2 monitores e 2 mouses. Vou começar verificando o custo de um monitor.  \n",
      "AÇÃO: obter_custo: monitor  \n",
      "PAUSA\n",
      " -- executando --> obter_custo monitor  \n",
      "OBSERVAÇÃO: Demais itens custam R$ 199,00.\n",
      "PENSAMENTO: Agora que tenho o custo de um monitor e de um mouse, posso calcular o total. O custo de um monitor é R$ 799,00 e o custo de um mouse é R$ 199,00. Vou calcular o total para 2 monitores e 2 mouses.  \n",
      "AÇÃO: calcular: (799 * 2) + (199 * 2)  \n",
      "PAUSA\n",
      " -- executando --> calcular (799 * 2) + (199 * 2)  \n",
      "OBSERVAÇÃO: 1996.0\n",
      "RESPOSTA: O total que você vai pagar por 2 monitores e 2 mouses é R$ 1.996,00.\n"
     ]
    }
   ],
   "source": [
    "pergunta = \"Quero comprar 2 monitores and 2 mouses. Quanto que eu vou pagar?\"\n",
    "chamar_agente(pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3042ee15-2073-4bfc-a116-18364535dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Eu deveria procurar Andrew Ng no Wikipedia para obter informações sobre ele. \n",
      "AÇÃO: wikipedia: Andrew Ng\n",
      "PAUSA\n",
      " -- executando --> wikipedia Andrew Ng\n",
      "OBSERVAÇÃO: <span class=\"searchmatch\">Andrew</span> Yan-Tak <span class=\"searchmatch\">Ng</span> (Chinese: 吳恩達; born 1976) is a British-American computer scientist and technology entrepreneur focusing on machine learning and artificial\n",
      "RESPOSTA: Andrew Ng é um cientista da computação e empreendedor tecnológico britânico-americano, nascido em 1976, que se concentra em aprendizado de máquina e inteligência artificial.\n"
     ]
    }
   ],
   "source": [
    "pergunta = \"Andrew Ng\"\n",
    "chamar_agente(pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b715f764-6320-41ae-82f9-09db1174c9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENSAMENTO: Eu deveria obter a temperatura atual na cidade de Lisboa usando obter_clima_atual.  \n",
      "AÇÃO: obter_clima_atual: Lisboa  \n",
      "PAUSA\n",
      " -- executando --> obter_clima_atual Lisboa  \n",
      "OBSERVAÇÃO: 20°C\n",
      "RESPOSTA: A temperatura atual em Lisboa é 20°C.\n"
     ]
    }
   ],
   "source": [
    "pergunta = \"Como está o tempo em Lisboa agora?\"\n",
    "chamar_agente(pergunta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
